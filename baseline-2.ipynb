{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-12T19:19:59.574044Z",
     "iopub.status.busy": "2025-04-12T19:19:59.573754Z",
     "iopub.status.idle": "2025-04-12T19:20:01.874255Z",
     "shell.execute_reply": "2025-04-12T19:20:01.873547Z",
     "shell.execute_reply.started": "2025-04-12T19:19:59.574014Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:20:01.875478Z",
     "iopub.status.busy": "2025-04-12T19:20:01.875061Z",
     "iopub.status.idle": "2025-04-12T19:20:01.879619Z",
     "shell.execute_reply": "2025-04-12T19:20:01.878615Z",
     "shell.execute_reply.started": "2025-04-12T19:20:01.875448Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_path = \"/kaggle/input/datasettvt/conv_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:20:01.880695Z",
     "iopub.status.busy": "2025-04-12T19:20:01.880405Z",
     "iopub.status.idle": "2025-04-12T19:20:02.055744Z",
     "shell.execute_reply": "2025-04-12T19:20:02.054864Z",
     "shell.execute_reply.started": "2025-04-12T19:20:01.880663Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_dataset = load_from_disk(os.path.join(dataset_path, \"therapy_train\"))\n",
    "val_dataset = load_from_disk(os.path.join(dataset_path, \"therapy_val\"))\n",
    "test_dataset = load_from_disk(os.path.join(dataset_path, \"therapy_test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:20:02.058127Z",
     "iopub.status.busy": "2025-04-12T19:20:02.057791Z",
     "iopub.status.idle": "2025-04-12T19:20:02.085591Z",
     "shell.execute_reply": "2025-04-12T19:20:02.084707Z",
     "shell.execute_reply.started": "2025-04-12T19:20:02.058096Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Dataset Samples:\n",
      "{'input_text': 'T: Hi you how to do it today? [SEP] P: Great. How are you?', 'target_text': \"I'm doing well. Thanks for asking.\"}\n",
      "{'input_text': \"T: Hi you how to do it today? [SEP] P: Great. How are you? [SEP] T: I'm doing well. Thanks for asking.\", 'target_text': \"So you're doing great.\"}\n",
      "{'input_text': \"T: Hi you how to do it today? [SEP] P: Great. How are you? [SEP] T: I'm doing well. Thanks for asking. [SEP] T: So you're doing great. [SEP] P: I'm doing awesome.\", 'target_text': \"I know your brother brought you in today and he had expressed some concerns about your mood. Do you know what that's about?\"}\n",
      "{'input_text': \"T: Hi you how to do it today? [SEP] P: Great. How are you? [SEP] T: I'm doing well. Thanks for asking. [SEP] T: So you're doing great. [SEP] P: I'm doing awesome. [SEP] T: I know your brother brought you in today and he had expressed some concerns about your mood. Do you know what that's about? [SEP] P: I, I think he's worrying for no reason. Because I, you know, I for the last like week and a half, I have been following my passion, which is baking. And I didn't realize this before, because I worked in an office. And I just realized that that's not what I want to do with my life. And I know what I want to do with my life now, and I've never known before. So this is an amazing feeling. And what I want to do is I want to start my own baking business. And so what happened was That a couple. Two weeks ago, my nephew had a bake sale. And I've always I've always been like baking, but I've always been like from the box or like from, you know, whatever. So I tried for the first time making brownies from scratch and they were amazing and everyone loved them at the bake sale and they sold out. And my nephew thought I was a hero, basically, I was and so now it made me realize like I could do this for a living and it would make me feel amazing and make me feel like a hero for all these people. And like my college campus would be kind of cool if I could like put up something about like delivering the bakery like the dorms or like big goods to dorms because you know, college students love that type of thing. But so anyway, so I was thinking about long story short, having this business and I would bake all these cookies and I was gonna put up flyers because I don't I'm not like at the point where I can get like an office space but I don't need an office space because I have my apartment and I have everything I need in my apartment to bake everything I need. And I can also have a BJs membership. So Go to BJs. And I can get everything I need in bulk. So like all the flour and butter and sugar and all that stuff. So it's not an issue if I just do it from my apartment. And so I was putting up flyers and trying to promote my business and has really been working on for the last week and a half, and I feel great. And it's amazing. And that's basically it.\", 'target_text': \"Alright, so you feel like, everything's kind of going your way. Hmm. And you're really excited about the new business idea. I know that your brother was a little concerned with how much you've been spending on the business idea. And he mentioned some things about different relationships you've had that are new.\"}\n",
      "{'input_text': \"T: Hi you how to do it today? [SEP] P: Great. How are you? [SEP] T: I'm doing well. Thanks for asking. [SEP] T: So you're doing great. [SEP] P: I'm doing awesome. [SEP] T: I know your brother brought you in today and he had expressed some concerns about your mood. Do you know what that's about? [SEP] P: I, I think he's worrying for no reason. Because I, you know, I for the last like week and a half, I have been following my passion, which is baking. And I didn't realize this before, because I worked in an office. And I just realized that that's not what I want to do with my life. And I know what I want to do with my life now, and I've never known before. So this is an amazing feeling. And what I want to do is I want to start my own baking business. And so what happened was That a couple. Two weeks ago, my nephew had a bake sale. And I've always I've always been like baking, but I've always been like from the box or like from, you know, whatever. So I tried for the first time making brownies from scratch and they were amazing and everyone loved them at the bake sale and they sold out. And my nephew thought I was a hero, basically, I was and so now it made me realize like I could do this for a living and it would make me feel amazing and make me feel like a hero for all these people. And like my college campus would be kind of cool if I could like put up something about like delivering the bakery like the dorms or like big goods to dorms because you know, college students love that type of thing. But so anyway, so I was thinking about long story short, having this business and I would bake all these cookies and I was gonna put up flyers because I don't I'm not like at the point where I can get like an office space but I don't need an office space because I have my apartment and I have everything I need in my apartment to bake everything I need. And I can also have a BJs membership. So Go to BJs. And I can get everything I need in bulk. So like all the flour and butter and sugar and all that stuff. So it's not an issue if I just do it from my apartment. And so I was putting up flyers and trying to promote my business and has really been working on for the last week and a half, and I feel great. And it's amazing. And that's basically it. [SEP] T: Alright, so you feel like, everything's kind of going your way. Hmm. And you're really excited about the new business idea. I know that your brother was a little concerned with how much you've been spending on the business idea. And he mentioned some things about different relationships you've had that are new. [SEP] P: Okay, so there's a couple that with that. So with the spending, like I don't think my brother recognizes that when you start a business like you need to invest in it to begin, and I understand why he's worried because like, so at work well at the office job that I had, like I got in trouble and because I obviously you need to make fires and I was like, oh, like he doesn't realize I'm frugal. I'm smart. So I was like I'll make the fires at work. And put them out of the work computer. So that I'm not having to pay like, wherever, like staples or something to go and print them out for me. So I got in trouble because it was like for personal use, and I was using like the, the work, whatever. But like that's what annoys me about it because like the new guy that I met, which is the other thing with the relationships, like this new guy is so supportive of my ideas. I met him actually in a bakery, which is like destiny. And he was so supportive when I told him about what I was planning. And actually the other guy that I was talking to before, and I've been talking to him for a while, he was kind of like my brother and was like, are you sure this is something you want to do? And like, I don't understand why you would say that someone who's obviously sure of what they want to do. Like, I know I can do it. I know that I'll be successful, like, did they not taste the brownies at the bake sale? Like they were amazing. And so that's kind of where I am and that's why my brother's worried but he shouldn't be because like I have all this played out.\", 'target_text': \"He's worried that you don't want to think this was the new relationship you don't know the guy too well\"}\n",
      "\n",
      "Validation Dataset Samples:\n",
      "{'input_text': \"T: I saw the smoking sign outside and I like this. How are the signs working for you? [SEP] P: Uh, you know, when I print them out properly, they're working pretty well, but whatever. Yeah. It's really making me feel guilty about smoking so i have been smoking less.\", 'target_text': \"That's really really good. So how's the job situation coming along?\"}\n",
      "{'input_text': \"T: I saw the smoking sign outside and I like this. How are the signs working for you? [SEP] P: Uh, you know, when I print them out properly, they're working pretty well, but whatever. Yeah. It's really making me feel guilty about smoking so i have been smoking less. [SEP] T: That's really really good. So how's the job situation coming along? [SEP] P: I don't know. It's, it kind of sucks. To be honest. It was late. Last shift, and my boss was like giving me that, you know, stare of like death. And I'm like, you know, thinking, why do I keep doing this?\", 'target_text': 'Why? Why were you late?'}\n",
      "{'input_text': \"T: I saw the smoking sign outside and I like this. How are the signs working for you? [SEP] P: Uh, you know, when I print them out properly, they're working pretty well, but whatever. Yeah. It's really making me feel guilty about smoking so i have been smoking less. [SEP] T: That's really really good. So how's the job situation coming along? [SEP] P: I don't know. It's, it kind of sucks. To be honest. It was late. Last shift, and my boss was like giving me that, you know, stare of like death. And I'm like, you know, thinking, why do I keep doing this? [SEP] T: Why? Why were you late? [SEP] P: I just I keep missing the bus. And that's a stupid excuse.\", 'target_text': \"first Why don't we put a list on the door to tell you You know what you need to go to work? You know, don't forget any of your paraphernalia. So you're making your lists. Are you checking them twice?\"}\n",
      "{'input_text': \"T: I saw the smoking sign outside and I like this. How are the signs working for you? [SEP] P: Uh, you know, when I print them out properly, they're working pretty well, but whatever. Yeah. It's really making me feel guilty about smoking so i have been smoking less. [SEP] T: That's really really good. So how's the job situation coming along? [SEP] P: I don't know. It's, it kind of sucks. To be honest. It was late. Last shift, and my boss was like giving me that, you know, stare of like death. And I'm like, you know, thinking, why do I keep doing this? [SEP] T: Why? Why were you late? [SEP] P: I just I keep missing the bus. And that's a stupid excuse. [SEP] T: first Why don't we put a list on the door to tell you You know what you need to go to work? You know, don't forget any of your paraphernalia. So you're making your lists. Are you checking them twice? [SEP] P: Like 10 times.\", 'target_text': 'But are they working for you?'}\n",
      "{'input_text': \"T: I saw the smoking sign outside and I like this. How are the signs working for you? [SEP] P: Uh, you know, when I print them out properly, they're working pretty well, but whatever. Yeah. It's really making me feel guilty about smoking so i have been smoking less. [SEP] T: That's really really good. So how's the job situation coming along? [SEP] P: I don't know. It's, it kind of sucks. To be honest. It was late. Last shift, and my boss was like giving me that, you know, stare of like death. And I'm like, you know, thinking, why do I keep doing this? [SEP] T: Why? Why were you late? [SEP] P: I just I keep missing the bus. And that's a stupid excuse. [SEP] T: first Why don't we put a list on the door to tell you You know what you need to go to work? You know, don't forget any of your paraphernalia. So you're making your lists. Are you checking them twice? [SEP] P: Like 10 times. [SEP] T: But are they working for you? [SEP] P: Yeah.\", 'target_text': 'And I noticed your yoga mats here. Have you been using it?'}\n",
      "\n",
      "Test Dataset Samples:\n",
      "{'input_text': \"T: So, alright, let's take a step back and talk about competency. What education Did you need for the job you have now? [SEP] P: I have my bachelor's degree. And we got a little bit of training. You know every so often we get some training at work and stuff like that.\", 'target_text': \"Are you evaluated at work by anybody to see if you're in a job you should be?\"}\n",
      "{'input_text': \"T: So, alright, let's take a step back and talk about competency. What education Did you need for the job you have now? [SEP] P: I have my bachelor's degree. And we got a little bit of training. You know every so often we get some training at work and stuff like that. [SEP] T: Are you evaluated at work by anybody to see if you're in a job you should be? [SEP] P: Yeah, I have a supervisor so they check up on stuff and also like if I feel like I have questions and stuff like that, I can go to them as well.\", 'target_text': \"Have you been Found in that system to be somebody who's satisfying the requirements of in terms of competency satisfy the requirements of employee.\"}\n",
      "{'input_text': \"T: So, alright, let's take a step back and talk about competency. What education Did you need for the job you have now? [SEP] P: I have my bachelor's degree. And we got a little bit of training. You know every so often we get some training at work and stuff like that. [SEP] T: Are you evaluated at work by anybody to see if you're in a job you should be? [SEP] P: Yeah, I have a supervisor so they check up on stuff and also like if I feel like I have questions and stuff like that, I can go to them as well. [SEP] T: Have you been Found in that system to be somebody who's satisfying the requirements of in terms of competency satisfy the requirements of employee. [SEP] P: Yeah, I mean, I haven't been fired. So that's a good sign again,\", 'target_text': \"that's a good sign. Yeah, you haven't been fired. Have you ever had any type of write up or somebody discussing something with you?\"}\n",
      "{'input_text': \"T: So, alright, let's take a step back and talk about competency. What education Did you need for the job you have now? [SEP] P: I have my bachelor's degree. And we got a little bit of training. You know every so often we get some training at work and stuff like that. [SEP] T: Are you evaluated at work by anybody to see if you're in a job you should be? [SEP] P: Yeah, I have a supervisor so they check up on stuff and also like if I feel like I have questions and stuff like that, I can go to them as well. [SEP] T: Have you been Found in that system to be somebody who's satisfying the requirements of in terms of competency satisfy the requirements of employee. [SEP] P: Yeah, I mean, I haven't been fired. So that's a good sign again, [SEP] T: that's a good sign. Yeah, you haven't been fired. Have you ever had any type of write up or somebody discussing something with you? [SEP] P: No, I just I kind of feel like maybe the climate has changed a little bit at the office after this happened, like maybe other people think I didn't make the right decision. I guess maybe that's part of where all my doubts are coming from, like, no one has said to me and I have, you know, my supervisor hasn't called me in and said, I'm concerned about this, but I just feel like maybe  other people think that I did something wrong.\", 'target_text': \"Alright, so there's no there's no evidence supporting that. In a kind of a direct fashion, like a supervisor coming to, but there's no other evidence supporting it based on your, what you're feeling, how you're perceiving things. Yeah, you're getting this feeling that, by the way, they're interacting with you.\"}\n",
      "{'input_text': \"T: So, alright, let's take a step back and talk about competency. What education Did you need for the job you have now? [SEP] P: I have my bachelor's degree. And we got a little bit of training. You know every so often we get some training at work and stuff like that. [SEP] T: Are you evaluated at work by anybody to see if you're in a job you should be? [SEP] P: Yeah, I have a supervisor so they check up on stuff and also like if I feel like I have questions and stuff like that, I can go to them as well. [SEP] T: Have you been Found in that system to be somebody who's satisfying the requirements of in terms of competency satisfy the requirements of employee. [SEP] P: Yeah, I mean, I haven't been fired. So that's a good sign again, [SEP] T: that's a good sign. Yeah, you haven't been fired. Have you ever had any type of write up or somebody discussing something with you? [SEP] P: No, I just I kind of feel like maybe the climate has changed a little bit at the office after this happened, like maybe other people think I didn't make the right decision. I guess maybe that's part of where all my doubts are coming from, like, no one has said to me and I have, you know, my supervisor hasn't called me in and said, I'm concerned about this, but I just feel like maybe  other people think that I did something wrong. [SEP] T: Alright, so there's no there's no evidence supporting that. In a kind of a direct fashion, like a supervisor coming to, but there's no other evidence supporting it based on your, what you're feeling, how you're perceiving things. Yeah, you're getting this feeling that, by the way, they're interacting with you. [SEP] P: Yeah. Which, I guess maybe I shouldn't be that freaked out about because there have been other people who have made mistakes and like, the supervisors have talked to them and, you know, even then they didn't lose their jobs. So it's not like, you know, I, you know, I don't know, I guess it's not like just hearing them, or thinking that they're judging me is an indication that something terrible is going to happen or that I made this huge mistake.\", 'target_text': \"Alright, so you can see that I'm talking this through you can see that. So some of this could be feelings. Thoughts you're having, combined with what you're actually observing share, you're filtering your observations in a way that's maybe making them seem a little more destructive, or more negative.\"}\n"
     ]
    }
   ],
   "source": [
    "# Function to print 5 examples from a dataset\n",
    "def print_examples(dataset, name):\n",
    "    print(f\"\\n{name} Dataset Samples:\")\n",
    "    for i in range(5):\n",
    "        print(dataset[i])  # Prints the first 5 examples\n",
    "\n",
    "# Print examples\n",
    "print_examples(train_dataset, \"Train\")\n",
    "print_examples(val_dataset, \"Validation\")\n",
    "print_examples(test_dataset, \"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:20:48.504238Z",
     "iopub.status.busy": "2025-04-12T19:20:48.503790Z",
     "iopub.status.idle": "2025-04-12T19:20:54.598186Z",
     "shell.execute_reply": "2025-04-12T19:20:54.597356Z",
     "shell.execute_reply.started": "2025-04-12T19:20:48.504198Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
      "Collecting bleu\n",
      "  Downloading bleu-0.3.tar.gz (5.2 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: bert-score in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\n",
      "Collecting efficiency (from bleu)\n",
      "  Downloading efficiency-2.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score) (3.7.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Downloading efficiency-2.0-py3-none-any.whl (32 kB)\n",
      "Building wheels for collected packages: bleu\n",
      "  Building wheel for bleu (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for bleu: filename=bleu-0.3-py3-none-any.whl size=5781 sha256=f91a0c3f74f588838b9ff3737ce849c9e990eed6c5612dd03bb5070cf272630e\n",
      "  Stored in directory: /root/.cache/pip/wheels/c6/d8/d1/009abe01b8b2c6a14c62d197b510b3cc1076014c22d712c5ce\n",
      "Successfully built bleu\n",
      "Installing collected packages: efficiency, bleu\n",
      "Successfully installed bleu-0.3 efficiency-2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets bleu bert-score torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:21:07.939887Z",
     "iopub.status.busy": "2025-04-12T19:21:07.939492Z",
     "iopub.status.idle": "2025-04-12T19:21:07.944250Z",
     "shell.execute_reply": "2025-04-12T19:21:07.943496Z",
     "shell.execute_reply.started": "2025-04-12T19:21:07.939853Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:21:10.530733Z",
     "iopub.status.busy": "2025-04-12T19:21:10.530431Z",
     "iopub.status.idle": "2025-04-12T19:21:13.295276Z",
     "shell.execute_reply": "2025-04-12T19:21:13.294601Z",
     "shell.execute_reply.started": "2025-04-12T19:21:10.530710Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1566542459514492a7efd94278e169f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad58e83357314aac892f7bdd8217a2ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc659834c209488e98d3534f072d2864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1167f7188d4ac3b3b42939c5fc01fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "\n",
    "# Dataset class for tokenizing input & target text\n",
    "class ConversationDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        input_text = \"predict next utterance: \" + sample[\"input_text\"]\n",
    "        target_text = sample[\"target_text\"]\n",
    "\n",
    "        # Tokenize input and target\n",
    "        inputs = self.tokenizer(\n",
    "            input_text, max_length=self.max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
    "        )\n",
    "        targets = self.tokenizer(\n",
    "            target_text, max_length=50, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": targets[\"input_ids\"].squeeze()\n",
    "        }\n",
    "\n",
    "# Convert datasets to PyTorch format\n",
    "train_data = ConversationDataset(train_dataset, tokenizer)\n",
    "val_data = ConversationDataset(val_dataset, tokenizer)\n",
    "test_data = ConversationDataset(test_dataset, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:21:29.754664Z",
     "iopub.status.busy": "2025-04-12T19:21:29.754349Z",
     "iopub.status.idle": "2025-04-12T19:22:24.881557Z",
     "shell.execute_reply": "2025-04-12T19:22:24.880930Z",
     "shell.execute_reply.started": "2025-04-12T19:21:29.754641Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90aa7cfe0e22439b9493f6a6b3dd6468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e720014a399b4fea927e3c5b1317f88d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce0fed61e0d5422798943adb3495c08f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "<ipython-input-10-7a517d0dfebe>:23: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\")\n",
    "\n",
    "# Define training parameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=[],\n",
    "\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    tokenizer=tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:22:29.107633Z",
     "iopub.status.busy": "2025-04-12T19:22:29.107342Z",
     "iopub.status.idle": "2025-04-12T20:23:43.081497Z",
     "shell.execute_reply": "2025-04-12T20:23:43.080578Z",
     "shell.execute_reply.started": "2025-04-12T19:22:29.107610Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5010' max='5010' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5010/5010 1:01:11, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.493800</td>\n",
       "      <td>1.467256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.454800</td>\n",
       "      <td>1.446475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.437100</td>\n",
       "      <td>1.438808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.422400</td>\n",
       "      <td>1.433112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.423100</td>\n",
       "      <td>1.429076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.378800</td>\n",
       "      <td>1.428678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.382500</td>\n",
       "      <td>1.427278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.321000</td>\n",
       "      <td>1.426620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.367800</td>\n",
       "      <td>1.426880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.339000</td>\n",
       "      <td>1.427133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5010, training_loss=1.6354563094422727, metrics={'train_runtime': 3673.5397, 'train_samples_per_second': 10.91, 'train_steps_per_second': 1.364, 'total_flos': 2.744507468611584e+16, 'train_loss': 1.6354563094422727, 'epoch': 10.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T22:41:22.059030Z",
     "iopub.status.busy": "2025-03-20T22:41:22.058786Z",
     "iopub.status.idle": "2025-03-20T22:41:22.614027Z",
     "shell.execute_reply": "2025-03-20T22:41:22.613292Z",
     "shell.execute_reply.started": "2025-03-20T22:41:22.059009Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/kaggle/working/t5_therapy_model/tokenizer_config.json',\n",
       " '/kaggle/working/t5_therapy_model/special_tokens_map.json',\n",
       " '/kaggle/working/t5_therapy_model/spiece.model',\n",
       " '/kaggle/working/t5_therapy_model/added_tokens.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"/kaggle/working/t5_therapy_model\")\n",
    "tokenizer.save_pretrained(\"/kaggle/working/t5_therapy_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T20:23:50.236943Z",
     "iopub.status.busy": "2025-04-12T20:23:50.236645Z",
     "iopub.status.idle": "2025-04-12T20:23:52.764405Z",
     "shell.execute_reply": "2025-04-12T20:23:52.763698Z",
     "shell.execute_reply.started": "2025-04-12T20:23:50.236917Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input: T: So, alright, let's take a step back and talk about competency. What education Did you need for the job you have now? [SEP] P: I have my bachelor's degree. And we got a little bit of training. You know every so often we get some training at work and stuff like that.\n",
      "Actual: Are you evaluated at work by anybody to see if you're in a job you should be?\n",
      "Generated: You have a bachelor's degree?\n",
      "\n",
      "Input: T: So, alright, let's take a step back and talk about competency. What education Did you need for the job you have now? [SEP] P: I have my bachelor's degree. And we got a little bit of training. You know every so often we get some training at work and stuff like that. [SEP] T: Are you evaluated at work by anybody to see if you're in a job you should be? [SEP] P: Yeah, I have a supervisor so they check up on stuff and also like if I feel like I have questions and stuff like that, I can go to them as well.\n",
      "Actual: Have you been Found in that system to be somebody who's satisfying the requirements of in terms of competency satisfy the requirements of employee.\n",
      "Generated: Is there anything else you want to talk about?\n",
      "\n",
      "Input: T: So, alright, let's take a step back and talk about competency. What education Did you need for the job you have now? [SEP] P: I have my bachelor's degree. And we got a little bit of training. You know every so often we get some training at work and stuff like that. [SEP] T: Are you evaluated at work by anybody to see if you're in a job you should be? [SEP] P: Yeah, I have a supervisor so they check up on stuff and also like if I feel like I have questions and stuff like that, I can go to them as well. [SEP] T: Have you been Found in that system to be somebody who's satisfying the requirements of in terms of competency satisfy the requirements of employee. [SEP] P: Yeah, I mean, I haven't been fired. So that's a good sign again,\n",
      "Actual: that's a good sign. Yeah, you haven't been fired. Have you ever had any type of write up or somebody discussing something with you?\n",
      "Generated: Have you ever been fired?\n",
      "\n",
      "Input: T: So, alright, let's take a step back and talk about competency. What education Did you need for the job you have now? [SEP] P: I have my bachelor's degree. And we got a little bit of training. You know every so often we get some training at work and stuff like that. [SEP] T: Are you evaluated at work by anybody to see if you're in a job you should be? [SEP] P: Yeah, I have a supervisor so they check up on stuff and also like if I feel like I have questions and stuff like that, I can go to them as well. [SEP] T: Have you been Found in that system to be somebody who's satisfying the requirements of in terms of competency satisfy the requirements of employee. [SEP] P: Yeah, I mean, I haven't been fired. So that's a good sign again, [SEP] T: that's a good sign. Yeah, you haven't been fired. Have you ever had any type of write up or somebody discussing something with you? [SEP] P: No, I just I kind of feel like maybe the climate has changed a little bit at the office after this happened, like maybe other people think I didn't make the right decision. I guess maybe that's part of where all my doubts are coming from, like, no one has said to me and I have, you know, my supervisor hasn't called me in and said, I'm concerned about this, but I just feel like maybe  other people think that I did something wrong.\n",
      "Actual: Alright, so there's no there's no evidence supporting that. In a kind of a direct fashion, like a supervisor coming to, but there's no other evidence supporting it based on your, what you're feeling, how you're perceiving things. Yeah, you're getting this feeling that, by the way, they're interacting with you.\n",
      "Generated: Okay, so that's a good sign that you're in a good position to be in a job.\n",
      "\n",
      "Input: T: So, alright, let's take a step back and talk about competency. What education Did you need for the job you have now? [SEP] P: I have my bachelor's degree. And we got a little bit of training. You know every so often we get some training at work and stuff like that. [SEP] T: Are you evaluated at work by anybody to see if you're in a job you should be? [SEP] P: Yeah, I have a supervisor so they check up on stuff and also like if I feel like I have questions and stuff like that, I can go to them as well. [SEP] T: Have you been Found in that system to be somebody who's satisfying the requirements of in terms of competency satisfy the requirements of employee. [SEP] P: Yeah, I mean, I haven't been fired. So that's a good sign again, [SEP] T: that's a good sign. Yeah, you haven't been fired. Have you ever had any type of write up or somebody discussing something with you? [SEP] P: No, I just I kind of feel like maybe the climate has changed a little bit at the office after this happened, like maybe other people think I didn't make the right decision. I guess maybe that's part of where all my doubts are coming from, like, no one has said to me and I have, you know, my supervisor hasn't called me in and said, I'm concerned about this, but I just feel like maybe  other people think that I did something wrong. [SEP] T: Alright, so there's no there's no evidence supporting that. In a kind of a direct fashion, like a supervisor coming to, but there's no other evidence supporting it based on your, what you're feeling, how you're perceiving things. Yeah, you're getting this feeling that, by the way, they're interacting with you. [SEP] P: Yeah. Which, I guess maybe I shouldn't be that freaked out about because there have been other people who have made mistakes and like, the supervisors have talked to them and, you know, even then they didn't lose their jobs. So it's not like, you know, I, you know, I don't know, I guess it's not like just hearing them, or thinking that they're judging me is an indication that something terrible is going to happen or that I made this huge mistake.\n",
      "Actual: Alright, so you can see that I'm talking this through you can see that. So some of this could be feelings. Thoughts you're having, combined with what you're actually observing share, you're filtering your observations in a way that's maybe making them seem a little more destructive, or more negative.\n",
      "Generated: Yeah, that's a good sign. Yeah, that's a good sign. Yeah, that's a good sign.\n"
     ]
    }
   ],
   "source": [
    "def generate_response(model, tokenizer, text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    input_text = \"predict next utterance: \" + text\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True).input_ids.to(device)\n",
    "    \n",
    "    output_ids = model.generate(input_ids, max_length=50, num_beams=5, early_stopping=True)\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "# Test predictions\n",
    "for i in range(5):\n",
    "    sample_input = test_dataset[i][\"input_text\"]\n",
    "    actual_output = test_dataset[i][\"target_text\"]\n",
    "    generated_output = generate_response(model, tokenizer, sample_input)\n",
    "\n",
    "    print(f\"\\nInput: {sample_input}\")\n",
    "    print(f\"Actual: {actual_output}\")\n",
    "    print(f\"Generated: {generated_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T20:23:43.082937Z",
     "iopub.status.busy": "2025-04-12T20:23:43.082669Z",
     "iopub.status.idle": "2025-04-12T20:23:50.235105Z",
     "shell.execute_reply": "2025-04-12T20:23:50.234266Z",
     "shell.execute_reply.started": "2025-04-12T20:23:43.082916Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.3.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.29.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.12)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m241.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T20:23:52.765788Z",
     "iopub.status.busy": "2025-04-12T20:23:52.765471Z",
     "iopub.status.idle": "2025-04-12T20:28:46.777429Z",
     "shell.execute_reply": "2025-04-12T20:28:46.776629Z",
     "shell.execute_reply.started": "2025-04-12T20:23:52.765754Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feea13bd138a42379005f1526cc9dced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049ad22a707e4bf088cf07ce32435f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3feccb286c8242dea3ecd8daaf8e24f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 968/968 [04:38<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BLEU Score: 0.003317928729847959\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cab84764fb84b9e80b43014556d5ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b37a7df57542f2b1f7a4c189f40fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654928f62bba4f69ae88ef3e658dac7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a50d38b6079463982a621e57e2be6e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "260ed51225ae419b94e11bfae9f7bbf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49836620e4cf41f3bbdea67c336b0efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d48b232dfbe4cac8a72cd230b23ae21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713e0999c97c4523b7c6b48928fca981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 5.15 seconds, 187.81 sentences/sec\n",
      "\n",
      "BERTScore:\n",
      "F1 mean: 0.8580193519592285\n",
      "Precision mean: 0.8706005215644836\n",
      "Recall mean: 0.846301257610321\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "from bert_score import score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load metrics\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "# Optional: also load BERTScore from Hugging Face if you prefer\n",
    "# bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "# Helper function to generate model predictions\n",
    "def generate_response(model, tokenizer, input_text, max_length=32):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=True).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_length=max_length)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Prepare predictions and references\n",
    "references = []\n",
    "predictions = []\n",
    "\n",
    "for i in tqdm(range(len(test_dataset))):\n",
    "    input_text = test_dataset[i][\"input_text\"]\n",
    "    target_text = test_dataset[i][\"target_text\"]\n",
    "\n",
    "    prediction = generate_response(model, tokenizer, input_text)\n",
    "    \n",
    "    references.append(target_text)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "# BLEU Score\n",
    "bleu_score = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\n",
    "print(\"\\nBLEU Score:\", bleu_score[\"bleu\"])\n",
    "\n",
    "# BERTScore\n",
    "P, R, F1 = score(predictions, references, lang=\"en\", verbose=True)\n",
    "print(\"\\nBERTScore:\")\n",
    "print(\"F1 mean:\", F1.mean().item())\n",
    "print(\"Precision mean:\", P.mean().item())\n",
    "print(\"Recall mean:\", R.mean().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T23:08:53.268245Z",
     "iopub.status.busy": "2025-03-20T23:08:53.267879Z",
     "iopub.status.idle": "2025-03-20T23:08:53.274036Z",
     "shell.execute_reply": "2025-03-20T23:08:53.273358Z",
     "shell.execute_reply.started": "2025-03-20T23:08:53.268219Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores saved to evaluation_scores.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract BERT F1 score\n",
    "bert_f1 = F1.mean().item()\n",
    "\n",
    "# Extract BLEU Score correctly\n",
    "bleu_value = bleu_score[\"score\"] if isinstance(bleu_score, dict) else bleu_score\n",
    "\n",
    "# Save scores to a text file\n",
    "with open(\"/kaggle/working/evaluation_scores.txt\", \"w\") as file:\n",
    "    file.write(f\"BLEU Score: {bleu_value:.2f}\\n\")\n",
    "    file.write(f\"BERT Score (F1): {bert_f1:.4f}\\n\")\n",
    "\n",
    "print(\"\\nScores saved to evaluation_scores.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6921396,
     "sourceId": 11102753,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
