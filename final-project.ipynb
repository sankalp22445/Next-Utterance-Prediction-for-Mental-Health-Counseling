{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11406834,"sourceType":"datasetVersion","datasetId":7145247}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets evaluate transformers peft accelerate sentencepiece","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T20:52:41.241766Z","iopub.execute_input":"2025-04-14T20:52:41.241985Z","iopub.status.idle":"2025-04-14T20:53:57.397153Z","shell.execute_reply.started":"2025-04-14T20:52:41.241961Z","shell.execute_reply":"2025-04-14T20:53:57.396249Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (7.0.0)\nRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.5.1+cu124)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, evaluate\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.3 fsspec-2024.12.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# -----------------------------------------\n# Imports\n# -----------------------------------------\nimport numpy as np\nimport torch\nfrom datasets import load_from_disk, DatasetDict\nfrom transformers import (\n    T5ForConditionalGeneration, T5Tokenizer,\n    MarianMTModel, MarianTokenizer,\n    Seq2SeqTrainer, Seq2SeqTrainingArguments,\n    DataCollatorForSeq2Seq\n)\nfrom peft import get_peft_model, LoraConfig, TaskType\nimport evaluate\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T20:53:57.399220Z","iopub.execute_input":"2025-04-14T20:53:57.399600Z","iopub.status.idle":"2025-04-14T20:54:23.408065Z","shell.execute_reply.started":"2025-04-14T20:53:57.399570Z","shell.execute_reply":"2025-04-14T20:54:23.407527Z"}},"outputs":[{"name":"stderr","text":"2025-04-14 20:54:10.266053: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1744664050.450752      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1744664050.498220      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# -----------------------------------------\n# 1. Load Dataset\n# -----------------------------------------\ntrain_path = \"/kaggle/input/convu-dataset/conv_data/therapy_train\"\nval_path = \"/kaggle/input/convu-dataset/conv_data/therapy_val\"\ntest_path = \"/kaggle/input/convu-dataset/conv_data/therapy_test\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T20:54:23.408696Z","iopub.execute_input":"2025-04-14T20:54:23.409265Z","iopub.status.idle":"2025-04-14T20:54:23.412752Z","shell.execute_reply.started":"2025-04-14T20:54:23.409243Z","shell.execute_reply":"2025-04-14T20:54:23.412012Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T20:54:23.413481Z","iopub.execute_input":"2025-04-14T20:54:23.414225Z","iopub.status.idle":"2025-04-14T20:54:23.432790Z","shell.execute_reply.started":"2025-04-14T20:54:23.414179Z","shell.execute_reply":"2025-04-14T20:54:23.432114Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"dataset = DatasetDict({\n    \"train\": load_from_disk(train_path),\n    \"validation\": load_from_disk(val_path),\n    \"test\": load_from_disk(test_path)\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T20:54:23.434597Z","iopub.execute_input":"2025-04-14T20:54:23.434792Z","iopub.status.idle":"2025-04-14T20:54:23.541695Z","shell.execute_reply.started":"2025-04-14T20:54:23.434776Z","shell.execute_reply":"2025-04-14T20:54:23.541011Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# -----------------------------------------\n# 4. Back Translation (Batch & Efficient)\n# -----------------------------------------\nen_to_fr = \"Helsinki-NLP/opus-mt-en-fr\"\nfr_to_en = \"Helsinki-NLP/opus-mt-fr-en\"\n\nen2fr_tok = MarianTokenizer.from_pretrained(en_to_fr)\nfr2en_tok = MarianTokenizer.from_pretrained(fr_to_en)\n\nen2fr_model = MarianMTModel.from_pretrained(en_to_fr).to(device)\nfr2en_model = MarianMTModel.from_pretrained(fr_to_en).to(device)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T20:54:23.542459Z","iopub.execute_input":"2025-04-14T20:54:23.542701Z","iopub.status.idle":"2025-04-14T20:55:23.927156Z","shell.execute_reply.started":"2025-04-14T20:54:23.542679Z","shell.execute_reply":"2025-04-14T20:55:23.926602Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65df5e4c7e4143f891498e6a414cc0d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"source.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2443b6df8a34a79800d3a3f688fd2e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"target.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac7dc3633e294738908e438dc903252e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ea4b7d8a09b4039b70b141661bb0c40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8088517cee9a4ff19f91090314ecb13a"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bda5507678d24c8d8070076eb7fd46fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"source.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fca57ec701c74a1792f15f4377f2b992"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"target.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ca6a4e00fbd481b8216cee87bf080d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92a960ac245e4cb18a799586d78aa19d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bea1edb6b414eb1a6ecee4866439e33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/301M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fb4a75baa8b466c8be0139747340a02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9732d4dffa3b4a11b4a8b768fb48291b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/301M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1584af50337540999a6239874cc72e52"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/301M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ed3c39c2fc047a49dccac4932397aaf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac0c4380515841d8ad9a42f9d95c2426"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"def batch_back_translate(dataset, batch_size=16):\n    augmented = []\n    for i in tqdm(range(0, len(dataset), batch_size), desc=\"Back Translating\"):\n        batch = dataset[i:i+batch_size]\n        texts = batch[\"input_text\"]\n\n        # EN â†’ FR\n        inputs = en2fr_tok(texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n        with torch.no_grad():\n            fr = en2fr_model.generate(**inputs, max_length=128)\n        fr_texts = en2fr_tok.batch_decode(fr, skip_special_tokens=True)\n\n        # FR â†’ EN\n        inputs = fr2en_tok(fr_texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n        with torch.no_grad():\n            en = fr2en_model.generate(**inputs, max_length=128)\n        en_texts = fr2en_tok.batch_decode(en, skip_special_tokens=True)\n\n        for j, new_input in enumerate(en_texts):\n            augmented.append({\n                \"input_text\": new_input,\n                \"target_text\": batch[\"target_text\"][j]\n            })\n    return augmented","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T20:55:23.928008Z","iopub.execute_input":"2025-04-14T20:55:23.928308Z","iopub.status.idle":"2025-04-14T20:55:23.934350Z","shell.execute_reply.started":"2025-04-14T20:55:23.928279Z","shell.execute_reply":"2025-04-14T20:55:23.933623Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from tqdm import tqdm\nfrom datasets import Dataset,concatenate_datasets\nbt_augmented = batch_back_translate(dataset[\"train\"], batch_size=16)\nbt_dataset = Dataset.from_list(bt_augmented)\ncombined_train = concatenate_datasets([dataset[\"train\"], bt_dataset])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T20:55:23.935179Z","iopub.execute_input":"2025-04-14T20:55:23.935476Z","iopub.status.idle":"2025-04-14T21:06:09.772341Z","shell.execute_reply.started":"2025-04-14T20:55:23.935446Z","shell.execute_reply":"2025-04-14T21:06:09.771572Z"}},"outputs":[{"name":"stderr","text":"Back Translating:   0%|          | 0/251 [00:00<?, ?it/s]Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/301M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ae8bb5855524370b669de37f87f433a"}},"metadata":{}},{"name":"stderr","text":"Back Translating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 251/251 [10:45<00:00,  2.57s/it]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# -----------------------------------------\n# 5. Add Difficulty & Curriculum Split\n# -----------------------------------------\ndef add_difficulty(example):\n    example[\"difficulty\"] = len(example[\"target_text\"].split())\n    return example\n\ncombined_train = combined_train.map(add_difficulty, load_from_cache_file=False,keep_in_memory=True)\ncombined_train = combined_train.sort(\"difficulty\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T21:06:09.773009Z","iopub.execute_input":"2025-04-14T21:06:09.773275Z","iopub.status.idle":"2025-04-14T21:06:10.159035Z","shell.execute_reply.started":"2025-04-14T21:06:09.773252Z","shell.execute_reply":"2025-04-14T21:06:10.158489Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8016 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32c2fd8b5a6a4d12bd008a1999b53b1b"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"n = len(combined_train)\nstage1 = combined_train.select(range(int(0.33 * n)))\nstage2 = combined_train.select(range(int(0.33 * n), int(0.66 * n)))\nstage3 = combined_train.select(range(int(0.66 * n), n))\nstages = [stage1, stage2, stage3]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T21:06:10.159781Z","iopub.execute_input":"2025-04-14T21:06:10.160019Z","iopub.status.idle":"2025-04-14T21:06:10.169225Z","shell.execute_reply.started":"2025-04-14T21:06:10.160002Z","shell.execute_reply":"2025-04-14T21:06:10.168526Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# -----------------------------------------\n# 6. Tokenization\n# -----------------------------------------\nmodel_name = \"google/flan-t5-base\"\ntokenizer = T5Tokenizer.from_pretrained(model_name)\n\ndef preprocess_function(examples):\n    inputs = [f\"Respond appropriately: {x}\" for x in examples[\"input_text\"]]\n    targets = examples[\"target_text\"]\n    model_inputs = tokenizer(inputs, max_length=128, padding=\"max_length\", truncation=True)\n    labels = tokenizer(targets, max_length=32, padding=\"max_length\", truncation=True)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T21:06:10.170097Z","iopub.execute_input":"2025-04-14T21:06:10.170351Z","iopub.status.idle":"2025-04-14T21:06:13.692549Z","shell.execute_reply.started":"2025-04-14T21:06:10.170324Z","shell.execute_reply":"2025-04-14T21:06:13.691947Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fbc55407d9e4fd68ed79eed5b479f39"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba65c8e8e77e4b2298958bf4e4bd694e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f641b151b524ee180576bd122b4d6e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec2f3a0b89fe4c37afd47df9295e9de7"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"tokenized_stages = [stage.map(preprocess_function, batched=True, load_from_cache_file=False,keep_in_memory=True) for stage in stages]\nval_dataset = dataset[\"validation\"].map(preprocess_function, batched=True, load_from_cache_file=False,keep_in_memory=True)\ntest_dataset = dataset[\"test\"].map(preprocess_function, batched=True, load_from_cache_file=False,keep_in_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T21:06:13.693295Z","iopub.execute_input":"2025-04-14T21:06:13.693547Z","iopub.status.idle":"2025-04-14T21:06:38.811229Z","shell.execute_reply.started":"2025-04-14T21:06:13.693524Z","shell.execute_reply":"2025-04-14T21:06:38.810663Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2645 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4b6cc78ca904ac2aa2a6c164bc706da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2645 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7244276bd2d841cab0101ab13feaa8db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2726 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a32c42afe94649dd9880a5fca799c6cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/576 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a676946899e402c987c5aa09afa4c38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/968 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af30a0f2af884ce58beedeab37c347a9"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# -----------------------------------------\n# 7. Load Model with LoRA\n# -----------------------------------------\nbase_model = T5ForConditionalGeneration.from_pretrained(model_name)\nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=32,\n    target_modules=[\"q\", \"v\"],\n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=TaskType.SEQ_2_SEQ_LM\n)\nmodel = get_peft_model(base_model, lora_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T21:06:38.811930Z","iopub.execute_input":"2025-04-14T21:06:38.812218Z","iopub.status.idle":"2025-04-14T21:06:43.837400Z","shell.execute_reply.started":"2025-04-14T21:06:38.812177Z","shell.execute_reply":"2025-04-14T21:06:43.836883Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d69b200c87843148d547fe2e88fd2e8"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f74923e0bc3145c199f6e4706ff10bd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c3dc7e8c75e40199ed7f8e6f8035979"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"./results\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=10,  # longer, since early stopping will handle exit\n    predict_with_generate=True,\n    weight_decay=0.01,\n    save_total_limit=2,\n    logging_steps=50,\n    logging_dir=\"./logs\",\n    report_to=[],\n                       \n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T21:06:43.839675Z","iopub.execute_input":"2025-04-14T21:06:43.839910Z","iopub.status.idle":"2025-04-14T21:06:43.867642Z","shell.execute_reply.started":"2025-04-14T21:06:43.839893Z","shell.execute_reply":"2025-04-14T21:06:43.866954Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding=\"max_length\")\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    tokenizer=tokenizer,\n    eval_dataset=val_dataset,\n    data_collator=data_collator, \n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T21:06:43.868458Z","iopub.execute_input":"2025-04-14T21:06:43.868707Z","iopub.status.idle":"2025-04-14T21:06:44.227029Z","shell.execute_reply.started":"2025-04-14T21:06:43.868689Z","shell.execute_reply":"2025-04-14T21:06:44.226467Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/3809680329.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\nNo label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"for i, stage in enumerate(tokenized_stages):\n    print(f\"\\nğŸš€ Training on Curriculum Stage {i+1}\")\n    trainer.train_dataset = stage\n    trainer.train(resume_from_checkpoint=False)\n    trainer.save_model(f\"./checkpoint_stage_{i+1}\")\n\n# Final model save\ntrainer.save_model(\"./curriculum_trained_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T21:06:44.227736Z","iopub.execute_input":"2025-04-14T21:06:44.227936Z","iopub.status.idle":"2025-04-14T22:36:44.939876Z","shell.execute_reply.started":"2025-04-14T21:06:44.227920Z","shell.execute_reply":"2025-04-14T22:36:44.939320Z"}},"outputs":[{"name":"stdout","text":"\nğŸš€ Training on Curriculum Stage 1\n","output_type":"stream"},{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3310' max='3310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3310/3310 29:41, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>22.752500</td>\n      <td>11.288176</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>5.062300</td>\n      <td>4.368904</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>4.258900</td>\n      <td>3.880708</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>3.428000</td>\n      <td>3.249779</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>2.696100</td>\n      <td>2.879253</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>2.264000</td>\n      <td>2.656487</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>1.964400</td>\n      <td>2.569405</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>1.802700</td>\n      <td>2.511531</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>1.668900</td>\n      <td>2.492690</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>1.666900</td>\n      <td>2.482574</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"\nğŸš€ Training on Curriculum Stage 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3310' max='3310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3310/3310 29:40, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.448800</td>\n      <td>2.238115</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2.256200</td>\n      <td>2.172983</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2.138600</td>\n      <td>2.140065</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2.141100</td>\n      <td>2.119948</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>2.079100</td>\n      <td>2.110487</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>2.078200</td>\n      <td>2.101434</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>2.050300</td>\n      <td>2.096441</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>2.062700</td>\n      <td>2.092739</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>2.011900</td>\n      <td>2.090856</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>2.027000</td>\n      <td>2.090077</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"\nğŸš€ Training on Curriculum Stage 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3410' max='3410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3410/3410 30:32, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>3.420700</td>\n      <td>2.092771</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3.388200</td>\n      <td>2.090630</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3.378400</td>\n      <td>2.088145</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>3.342900</td>\n      <td>2.090895</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>3.327100</td>\n      <td>2.096545</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>3.288600</td>\n      <td>2.096918</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>3.300200</td>\n      <td>2.097763</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>3.334100</td>\n      <td>2.098172</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>3.311000</td>\n      <td>2.099103</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>3.331700</td>\n      <td>2.098271</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"!pip install bert_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T23:02:46.250437Z","iopub.execute_input":"2025-04-14T23:02:46.250972Z","iopub.status.idle":"2025-04-14T23:02:49.482889Z","shell.execute_reply.started":"2025-04-14T23:02:46.250950Z","shell.execute_reply":"2025-04-14T23:02:49.482161Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: bert_score in /usr/local/lib/python3.11/dist-packages (0.3.13)\nRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.5.1+cu124)\nRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.2.3)\nRequirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.51.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert_score) (1.26.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.32.3)\nRequirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.67.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert_score) (3.7.5)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert_score) (24.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2024.12.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.30.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.5.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (3.2.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2025.1.31)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert_score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert_score) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->bert_score) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->bert_score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->bert_score) (2024.2.0)\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom transformers import default_data_collator\n\nbleu = evaluate.load(\"bleu\")\nbertscore = evaluate.load(\"bertscore\")\nmodel = T5ForConditionalGeneration.from_pretrained(\"./curriculum_trained_model\").to(device)\ntokenizer = T5Tokenizer.from_pretrained(\"./curriculum_trained_model\")\nmodel.eval()\n\ndataloader = DataLoader(test_dataset, batch_size=8, collate_fn=default_data_collator)\n\npredictions, references = [], []\n\nfor batch in dataloader:\n    input_ids = batch[\"input_ids\"].to(device)\n    attention_mask = batch[\"attention_mask\"].to(device)\n\n    with torch.no_grad():\n        outputs = model.generate(\n        input_ids=input_ids,\n        attention_mask=attention_mask,\n        max_length=128,\n        num_beams=5,\n        early_stopping=True,\n        no_repeat_ngram_size=3,  # <- This helps prevent repeating tokens\n        repetition_penalty=1.2   # <- Optional, to penalize word reuse\n    )\n        \n\n    preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n    labels = tokenizer.batch_decode(batch[\"labels\"], skip_special_tokens=True)\n\n    for pred, label in zip(preds, labels):\n        if label.strip():\n            predictions.append(pred)\n            references.append([label])\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T23:33:38.502516Z","iopub.execute_input":"2025-04-14T23:33:38.503095Z","iopub.status.idle":"2025-04-14T23:36:30.170628Z","shell.execute_reply.started":"2025-04-14T23:33:38.503069Z","shell.execute_reply":"2025-04-14T23:36:30.170017Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"final_bertscore = bertscore.compute(\n    predictions=predictions,\n    references=[ref[0] for ref in references],\n    lang=\"en\"\n)\n\nbleu = evaluate.load(\"bleu\")\nbleu_score = bleu.compute(predictions=predictions, references=references)\n\nprint(f\"\\nğŸ“Š Filtered BERTScore:\")\nprint(f\"F1:        {np.mean(final_bertscore['f1']):.4f}\")\nprint(f\"Precision: {np.mean(final_bertscore['precision']):.4f}\")\nprint(f\"Recall:    {np.mean(final_bertscore['recall']):.4f}\")\n\nprint(f\"\\nğŸ“Š BLEU Score: {bleu_score['bleu']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T23:36:53.705806Z","iopub.execute_input":"2025-04-14T23:36:53.706487Z","iopub.status.idle":"2025-04-14T23:36:59.782982Z","shell.execute_reply.started":"2025-04-14T23:36:53.706460Z","shell.execute_reply":"2025-04-14T23:36:59.782256Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nğŸ“Š Filtered BERTScore:\nF1:        0.8482\nPrecision: 0.8499\nRecall:    0.8469\n\nğŸ“Š BLEU Score: 0.0080\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"predictions, references, input_texts = [], [], []\n\nfor batch in dataloader:\n    input_ids = batch[\"input_ids\"].to(device)\n    attention_mask = batch[\"attention_mask\"].to(device)\n\n    with torch.no_grad():\n        outputs = model.generate(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            max_length=128,\n            num_beams=5,\n            early_stopping=True,\n            no_repeat_ngram_size=3,\n            repetition_penalty=1.2\n        )\n\n    preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n    labels = tokenizer.batch_decode(batch[\"labels\"], skip_special_tokens=True)\n    inputs = tokenizer.batch_decode(batch[\"input_ids\"], skip_special_tokens=True)\n\n    for inp, pred, label in zip(inputs, preds, labels):\n        if label.strip():\n            input_texts.append(inp)\n            predictions.append(pred)\n            references.append(label)\n\n# Save to CSV\ndf = pd.DataFrame({\n    \"input_text\": input_texts,\n    \"reference\": references,\n    \"prediction\": predictions\n})\ndf.to_csv(\"sample_predictions.csv\", index=False)\nprint(\"âœ… Saved all predictions to 'all_predictions.csv'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T23:56:10.043548Z","iopub.execute_input":"2025-04-14T23:56:10.044070Z","iopub.status.idle":"2025-04-14T23:59:10.946771Z","shell.execute_reply.started":"2025-04-14T23:56:10.044044Z","shell.execute_reply":"2025-04-14T23:59:10.946126Z"}},"outputs":[{"name":"stdout","text":"âœ… Saved all predictions to 'all_predictions.csv'\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"from transformers import pipeline\nemotion_classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", device=0 if torch.cuda.is_available() else -1)\n\n# Load emotion rewriter\nrewriter_model_name = \"mrm8488/t5-base-finetuned-emotion\"\nrewriter_tokenizer = T5Tokenizer.from_pretrained(rewriter_model_name)\nrewriter_model = T5ForConditionalGeneration.from_pretrained(rewriter_model_name).to(device)\n\n# Function to rewrite prediction based on emotion\ndef rewrite_with_emotion(pred, target_emotion):\n    prompt = f\"rewrite with {target_emotion} emotion: {pred}\"\n    inputs = rewriter_tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n    with torch.no_grad():\n        outputs = rewriter_model.generate(**inputs, max_length=64, num_beams=5)\n    return rewriter_tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n# Evaluate with emotion alignment\ndataloader = DataLoader(test_dataset, batch_size=8, collate_fn=default_data_collator)\n\npredictions, references = [], []\n\nfor batch in dataloader:\n    input_ids = batch[\"input_ids\"].to(device)\n    attention_mask = batch[\"attention_mask\"].to(device)\n\n    with torch.no_grad():\n        outputs = model.generate(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            max_length=128,\n            num_beams=5 , # Beam search\n            no_repeat_ngram_size=3,  # <- This helps prevent repeating tokens\n            repetition_penalty=1.2   \n            \n        )\n\n    preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n    labels = tokenizer.batch_decode(batch[\"labels\"], skip_special_tokens=True)\n\n    for pred, label in zip(preds, labels):\n        if not label.strip():\n            continue\n\n        # Emotion detection\n        pred_emotion = emotion_classifier(pred)[0]['label']\n        label_emotion = emotion_classifier(label)[0]['label']\n\n        # Rewrite if mismatch\n        if pred_emotion != label_emotion:\n            pred = rewrite_with_emotion(pred, label_emotion)\n\n        predictions.append(pred)\n        references.append([label])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T00:31:50.995145Z","iopub.execute_input":"2025-04-15T00:31:50.995476Z","iopub.status.idle":"2025-04-15T00:35:39.484492Z","shell.execute_reply.started":"2025-04-15T00:31:50.995454Z","shell.execute_reply":"2025-04-15T00:35:39.483627Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"final_bertscore = bertscore.compute(\n    predictions=predictions,\n    references=[ref[0] for ref in references],\n    lang=\"en\"\n)\n\nbleu = evaluate.load(\"bleu\")\nbleu_score = bleu.compute(predictions=predictions, references=references)\n\nprint(f\"\\nğŸ“Š Filtered BERTScore:\")\nprint(f\"F1:        {np.mean(final_bertscore['f1']):.4f}\")\nprint(f\"Precision: {np.mean(final_bertscore['precision']):.4f}\")\nprint(f\"Recall:    {np.mean(final_bertscore['recall']):.4f}\")\n\nprint(f\"\\nğŸ“Š BLEU Score: {bleu_score['bleu']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T00:35:39.485735Z","iopub.execute_input":"2025-04-15T00:35:39.485994Z","iopub.status.idle":"2025-04-15T00:35:43.556686Z","shell.execute_reply.started":"2025-04-15T00:35:39.485974Z","shell.execute_reply":"2025-04-15T00:35:43.555980Z"}},"outputs":[{"name":"stdout","text":"\nğŸ“Š Filtered BERTScore:\nF1:        0.8332\nPrecision: 0.8409\nRecall:    0.8261\n\nğŸ“Š BLEU Score: 0.0087\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}